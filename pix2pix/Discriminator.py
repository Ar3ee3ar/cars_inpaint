import tensorflow as tf

from .network import downsample, upsample

def Discriminator(input_shape = [256,256,3]):
  initializer = tf.random_normal_initializer(0., 0.02)

  inp = tf.keras.layers.Input(shape=input_shape, name='input_image')
  tar = tf.keras.layers.Input(shape=input_shape, name='target_image')

  # x = tf.keras.layers.concatenate([inp, tar])  # (batch_size, 256, 256, channels*2)
  x =  inp

  down1 = downsample(64, 4, apply_batchnorm = False)(x)  # (batch_size, 128, 128, 64)
  down2 = downsample(128, 4)(down1)  # (batch_size, 64, 64, 128)
  down3 = downsample(256, 4)(down2)  # (batch_size, 32, 32, 256)

  zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3)  # (batch_size, 34, 34, 256)
  conv = tf.keras.layers.Conv2D(512, 4, strides=1,
                                kernel_initializer=initializer,
                                use_bias=False)(zero_pad1)  # (batch_size, 31, 31, 512)

  batchnorm1 = tf.keras.layers.BatchNormalization()(conv)

  leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)

  zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu)  # (batch_size, 33, 33, 512)

  last = tf.keras.layers.Conv2D(1, 4, strides=1,
                                kernel_initializer=initializer)(zero_pad2)  # (batch_size, 30, 30, 1)

  return tf.keras.Model(inputs=inp, outputs=last)
  
def Discriminator_con(input_shape = [256,256,3]):
  initializer = tf.random_normal_initializer(0., 0.02)

  inp = tf.keras.layers.Input(shape=input_shape, name='input_image')
  tar = tf.keras.layers.Input(shape=input_shape, name='target_image')

  x = tf.keras.layers.concatenate([inp, tar])  # (batch_size, 256, 256, channels*2)
  # x =  inp

  down1 = downsample(64, 4, apply_batchnorm = False)(x)  # (batch_size, 128, 128, 64) # 4
  down2 = downsample(128, 4)(down1)  # (batch_size, 64, 64, 128) # 7
  down3 = downsample(256, 4)(down2)  # (batch_size, 32, 32, 256) # 16

  zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3)  # (batch_size, 34, 34, 256)
  conv = tf.keras.layers.Conv2D(512, 4, strides=1,
                                kernel_initializer=initializer,
                                use_bias=False)(zero_pad1)  # (batch_size, 31, 31, 512) # 34

  batchnorm1 = tf.keras.layers.BatchNormalization()(conv)

  leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)

  zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu)  # (batch_size, 33, 33, 512)

  last = tf.keras.layers.Conv2D(1, 4, strides=1,
                                kernel_initializer=initializer)(zero_pad2)  # (batch_size, 30, 30, 1) # 70

  return tf.keras.Model(inputs=[inp, tar], outputs=last)


def dilated_Discriminator(input_shape = [512,512,3]):
  initializer = tf.random_normal_initializer(0., 0.02)

  inp = tf.keras.layers.Input(shape=input_shape, name='input_image')
  tar = tf.keras.layers.Input(shape=input_shape, name='target_image')

  x = tf.keras.layers.concatenate([inp, tar])  # (batch_size, 512, 512, channels*2)
  x =  inp

  down1 = downsample(64, 4, apply_batchnorm=False)(x)  # (batch_size, 256, 256, 64) # 4
  down2 = downsample(128, 4)(down1)  # (batch_size, 128, 128, 128) # 7
  down3 = downsample(256, 4)(down2)  # (batch_size, 64, 64, 256) # 16
  down4 = downsample(512, 4)(down3)  # (batch_size, 32, 32, 256) # 34
  down5 = downsample(512, 4)(down4)  # (batch_size, 16, 16, 256) # 70

  zero_pad1 = tf.keras.layers.ZeroPadding2D()(down5)  # (batch_size, 18, 18, 256)
  conv = tf.keras.layers.Conv2D(512, 4, strides=1,
                                kernel_initializer=initializer,
                                use_bias=False)(zero_pad1)  # (batch_size, 15, 15, 512) # 142

  batchnorm1 = tf.keras.layers.BatchNormalization()(conv)

  leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)

  zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu)  # (batch_size, 17, 17, 512)

  last = tf.keras.layers.Conv2D(1, 4, strides=1,
                                kernel_initializer=initializer)(zero_pad2)  # (batch_size, 14, 14, 1) # 286

  return tf.keras.Model(inputs=[inp, tar], outputs=last)

def diffPatch_Discriminator(input_shape = [512,512,3],patch=70):
  if(patch==34):
    initializer = tf.random_normal_initializer(0., 0.02)

    inp = tf.keras.layers.Input(shape=input_shape, name='input_image')
    tar = tf.keras.layers.Input(shape=input_shape, name='target_image')

    x = tf.keras.layers.concatenate([inp, tar])  # (batch_size, 512, 512, channels*2)
    x =  inp

    down1 = downsample(64, 4, apply_batchnorm=False)(x)  # (batch_size, 256, 256, 64) # 4
    down2 = downsample(128, 4)(down1)  # (batch_size, 128, 128, 128) # 7
    # down3 = downsample(256, 4)(down2)  # (batch_size, 64, 64, 256) # 16
    # down4 = downsample(512, 4)(down3)  # (batch_size, 32, 32, 256) # 34
    # down5 = downsample(512, 4)(down4)  # (batch_size, 16, 16, 256) # 70

    zero_pad1 = tf.keras.layers.ZeroPadding2D()(down2)  # (batch_size, 18, 18, 256)
    conv = tf.keras.layers.Conv2D(512, 4, strides=1,
                                  kernel_initializer=initializer,
                                  use_bias=False)(zero_pad1)  # (batch_size, 15, 15, 512) # 142

    batchnorm1 = tf.keras.layers.BatchNormalization()(conv)

    leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)

    zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu)  # (batch_size, 17, 17, 512)

    last = tf.keras.layers.Conv2D(1, 4, strides=1,
                                  kernel_initializer=initializer)(zero_pad2)  # (batch_size, 14, 14, 1) # 286

    return tf.keras.Model(inputs=[inp, tar], outputs=last)
  elif(patch==70):
    initializer = tf.random_normal_initializer(0., 0.02)

    inp = tf.keras.layers.Input(shape=input_shape, name='input_image')
    tar = tf.keras.layers.Input(shape=input_shape, name='target_image')

    x = tf.keras.layers.concatenate([inp, tar])  # (batch_size, 512, 512, channels*2)
    x =  inp

    down1 = downsample(64, 4, apply_batchnorm=False)(x)  # (batch_size, 256, 256, 64) # 4
    down2 = downsample(128, 4)(down1)  # (batch_size, 128, 128, 128) # 7
    down3 = downsample(256, 4)(down2)  # (batch_size, 64, 64, 256) # 16
    # down4 = downsample(512, 4)(down3)  # (batch_size, 32, 32, 256) # 34
    # down5 = downsample(512, 4)(down4)  # (batch_size, 16, 16, 256) # 70

    zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3)  # (batch_size, 18, 18, 256)
    conv = tf.keras.layers.Conv2D(512, 4, strides=1,
                                  kernel_initializer=initializer,
                                  use_bias=False)(zero_pad1)  # (batch_size, 15, 15, 512) # 142

    batchnorm1 = tf.keras.layers.BatchNormalization()(conv)

    leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)

    zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu)  # (batch_size, 17, 17, 512)

    last = tf.keras.layers.Conv2D(1, 4, strides=1,
                                  kernel_initializer=initializer)(zero_pad2)  # (batch_size, 14, 14, 1) # 286

    return tf.keras.Model(inputs=[inp, tar], outputs=last)
  elif(patch==142):
    initializer = tf.random_normal_initializer(0., 0.02)

    inp = tf.keras.layers.Input(shape=input_shape, name='input_image')
    tar = tf.keras.layers.Input(shape=input_shape, name='target_image')

    x = tf.keras.layers.concatenate([inp, tar])  # (batch_size, 512, 512, channels*2)
    x =  inp

    down1 = downsample(64, 4, apply_batchnorm=False)(x)  # (batch_size, 256, 256, 64) # 4
    down2 = downsample(128, 4)(down1)  # (batch_size, 128, 128, 128) # 7
    down3 = downsample(256, 4)(down2)  # (batch_size, 64, 64, 256) # 16
    down4 = downsample(512, 4)(down3)  # (batch_size, 32, 32, 256) # 34
    # down5 = downsample(512, 4)(down4)  # (batch_size, 16, 16, 256) # 70

    zero_pad1 = tf.keras.layers.ZeroPadding2D()(down4)  # (batch_size, 18, 18, 256)
    conv = tf.keras.layers.Conv2D(512, 4, strides=1,
                                  kernel_initializer=initializer,
                                  use_bias=False)(zero_pad1)  # (batch_size, 15, 15, 512) # 142

    batchnorm1 = tf.keras.layers.BatchNormalization()(conv)

    leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)

    zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu)  # (batch_size, 17, 17, 512)

    last = tf.keras.layers.Conv2D(1, 4, strides=1,
                                  kernel_initializer=initializer)(zero_pad2)  # (batch_size, 14, 14, 1) # 286

    return tf.keras.Model(inputs=[inp, tar], outputs=last)
  elif(patch==286):
    initializer = tf.random_normal_initializer(0., 0.02)

    inp = tf.keras.layers.Input(shape=input_shape, name='input_image')
    tar = tf.keras.layers.Input(shape=input_shape, name='target_image')

    x = tf.keras.layers.concatenate([inp, tar])  # (batch_size, 512, 512, channels*2)
    x =  inp

    down1 = downsample(64, 4, apply_batchnorm=False)(x)  # (batch_size, 256, 256, 64) # 4
    down2 = downsample(128, 4)(down1)  # (batch_size, 128, 128, 128) # 7
    down3 = downsample(256, 4)(down2)  # (batch_size, 64, 64, 256) # 16
    down4 = downsample(512, 4)(down3)  # (batch_size, 32, 32, 256) # 34
    down5 = downsample(512, 4)(down4)  # (batch_size, 16, 16, 256) # 70

    zero_pad1 = tf.keras.layers.ZeroPadding2D()(down5)  # (batch_size, 18, 18, 256)
    conv = tf.keras.layers.Conv2D(512, 4, strides=1,
                                  kernel_initializer=initializer,
                                  use_bias=False)(zero_pad1)  # (batch_size, 15, 15, 512) # 142

    batchnorm1 = tf.keras.layers.BatchNormalization()(conv)

    leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)

    zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu)  # (batch_size, 17, 17, 512)

    last = tf.keras.layers.Conv2D(1, 4, strides=1,
                                  kernel_initializer=initializer)(zero_pad2)  # (batch_size, 14, 14, 1) # 286

    return tf.keras.Model(inputs=[inp, tar], outputs=last)
